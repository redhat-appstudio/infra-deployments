---
role: Agent
resources:
  requests:
    cpu: 512m
    memory: 4096Mi
  limits:
    cpu: 2000m
    memory: 4096Mi
customConfig:
  data_dir: /vector-data-dir
  api:
    enabled: true
    address: 127.0.0.1:8686
    playground: false
  sources:
    k8s_logs:
      type: kubernetes_logs
      rotate_wait_secs: 5
      glob_minimum_cooldown_ms: 500
      max_line_bytes: 3145728
      auto_partial_merge: true
      extra_label_selector: "app.kubernetes.io/managed-by in (tekton-pipelines,pipelinesascode.tekton.dev)"
  transforms:
    reduce_events:
      type: reduce
      inputs:
        - k8s_logs
      group_by:
        - file
      flush_period_ms: 2000
      end_every_period_ms: 2000
      merge_strategies:
        message: concat_newline
    remap_app_logs:
      type: remap
      inputs:
        - reduce_events
      source: |-
        .tmp = del(.)
        # Preserve original kubernetes fields for Loki labels
        if exists(.tmp.kubernetes.pod_uid) {
          .pod_id = del(.tmp.kubernetes.pod_uid)
        } else {
          .pod_id = "unknown_pod_id"
        }
        if exists(.tmp.kubernetes.pod_name) {
          .pod_name = del(.tmp.kubernetes.pod_name)
        } else {
          .pod_name = "unknown_pod"
        }
        if exists(.tmp.kubernetes.container_name) {
          .container = del(.tmp.kubernetes.container_name)
        } else {
          .container = "unknown_container"
        }
        if exists(.tmp.kubernetes.pod_namespace) {
          .namespace = del(.tmp.kubernetes.pod_namespace)
        } else {
          .namespace = "unlabeled"
        }
        # Handling Tekton-specific labels
        if exists(.tmp.kubernetes.pod_labels."tekton.dev/taskRunUID") {
          .taskRunUID = del(.tmp.kubernetes.pod_labels."tekton.dev/taskRunUID")
        } else {
          .taskRunUID = "none"
        }
        if exists(.tmp.kubernetes.pod_labels."tekton.dev/pipelineRunUID") {
          .pipelineRunUID = del(.tmp.kubernetes.pod_labels."tekton.dev/pipelineRunUID")
          .result = .pipelineRunUID
        } else {
          .result = .taskRunUID
        }
        # --- Start: Cronjob Specific Handling ---
        if exists(.tmp.kubernetes.pod_labels."job-name") {
          .job_name = del(.tmp.kubernetes.pod_labels."job-name")
          .log_type = "cronjob"
          if exists(.tmp.kubernetes.pod_labels."cronjob-name") {
            .cronjob_name = del(.tmp.kubernetes.pod_labels."cronjob-name")
          } else {
            # Using corrected regex pattern without \d
            .job_name = to_string(.job_name) ?? "default"
            if match(.job_name, r'^(.*)-[0-9]{8,10}$') {
              .cronjob_name = replace(.job_name, r'-[0-9]{8,10}$', "")
            } else {
              .cronjob_name = "unknown_cronjob"
            }
          }
          if exists(.tmp.kubernetes.pod_labels."controller-uid") {
              .job_uid = del(.tmp.kubernetes.pod_labels."controller-uid")
          }
        } else {
          .log_type = "application"
        }
        # --- End: Cronjob Specific Handling ---
        # Clean up temporary fields
        .message = del(.tmp.message)
        del(.tmp)
  sinks:
    loki:
      type: loki
      inputs: ["remap_app_logs"]
      # Direct connection to Loki service (no gateway)
      endpoint: "http://vector-kubearchive-log-collector-loki.product-kubearchive-logging.svc.cluster.local:3100"
      encoding:
        codec: "text"
        except_fields: ["tmp"]
      auth:
        strategy: "basic"
        user: "${LOKI_USERNAME}"
        password: "${LOKI_PASSWORD}"
      tenant_id: "kubearchive"
      request:
        headers:
          X-Scope-OrgID: kubearchive
        timeout_secs: 60
      batch:
        max_bytes: 2097152
        max_events: 1000
        timeout_secs: 10
      compression: "gzip"
      labels:
        job: "vector"
        pod_id: "{{`{{ pod_id }}`}}"
        container: "{{`{{ container }}`}}"
        namespace: "{{`{{ namespace }}`}}"
        pod: "{{`{{ pod_name }}`}}"
      buffer:
        type: "memory"
        max_events: 10000
        when_full: "drop_newest"
env:
  - name: LOKI_USERNAME
    valueFrom:
      secretKeyRef:
        name: kubearchive-loki
        key: USERNAME
  - name: LOKI_PASSWORD
    valueFrom:
      secretKeyRef:
        name: kubearchive-loki
        key: PASSWORD
nodeSelector:
  konflux-ci.dev/workload: konflux-tenants
tolerations:
  - effect: NoSchedule
    key: konflux-ci.dev/workload
    operator: Equal
    value: konflux-tenants
image:
  repository: quay.io/kubearchive/vector
  tag: 0.46.1-distroless-libc
serviceAccount:
  create: true
  name: vector-kubearchive-log-collector
securityContext:
  allowPrivilegeEscalation: false
  runAsUser: 0
  capabilities:
    drop:
    - CHOWN
    - DAC_OVERRIDE
    - FOWNER
    - FSETID
    - KILL
    - NET_BIND_SERVICE
    - SETGID
    - SETPCAP
    - SETUID
  readOnlyRootFilesystem: true
  seLinuxOptions:
    type: spc_t
  seccompProfile:
    type: RuntimeDefault

# Override default volumes to be more specific and secure
extraVolumes:
  - name: varlog
    hostPath:
      path: /var/log/pods
      type: Directory
  - name: varlibdockercontainers
    hostPath:
      path: /var/lib/containers
      type: DirectoryOrCreate

extraVolumeMounts:
  - name: varlog
    mountPath: /var/log/pods
    readOnly: true
  - name: varlibdockercontainers  
    mountPath: /var/lib/containers
    readOnly: true

# Configure Vector to use emptyDir for its default data volume instead of hostPath
persistence:
  enabled: false


