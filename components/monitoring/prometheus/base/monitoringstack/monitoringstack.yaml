apiVersion: v1
kind: Namespace
metadata:
  name: appstudio-monitoring
spec: {}
---
# Deploy Monitoring Stack
apiVersion: monitoring.rhobs/v1alpha1
kind: MonitoringStack
metadata:
  name: appstudio-federate-ms
  namespace: appstudio-monitoring
spec:
  # Used to select the ServiceMonitor in the appstudio-monitoring namespace
  # NOTE: there isn't a need for namespaceSelector
  resourceSelector:
    matchLabels:
      monitoring.rhobs/stack: appstudio-federate-ms
  logLevel: info # use debug for verbose logs
  retention: 3h
  prometheusConfig:
    replicas: 2  # ensures that at least one prometheus is running during upgrade
  alertmanagerConfig:
    disabled: true
  resources: # ensure that you provide sufficient amount of resources
    requests:
      cpu: 500m
      memory: 1Gi
---
# Grant permission to Federate In-Cluster Prometheus
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: appstudio-federate-ms-view
  labels:
    kubernetes.io/part-of: appstudio-federate-ms
    monitoring.rhobs/stack: appstudio-federate-ms
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-monitoring-view
subjects:
- kind: ServiceAccount
  # ServiceAccount used in the prometheus deployed by ObO.
  # SA name follows <monitoring stack name>-prometheus nomenclature
  name: appstudio-federate-ms-prometheus
  namespace: appstudio-monitoring
---
# Create ServiceMonitor for cluster prometheus Federation
apiVersion: monitoring.rhobs/v1
kind: ServiceMonitor
metadata:
  name: appstudio-federate-smon
  namespace: appstudio-monitoring
  labels:
    kubernetes.io/part-of: appstudio-federate-ms
    monitoring.rhobs/stack: appstudio-federate-ms
spec:
  selector: # use the prometheus service to create a "dummy" target.
    matchLabels:
      app.kubernetes.io/managed-by: observability-operator
      app.kubernetes.io/name: appstudio-federate-ms-prometheus
  endpoints:
  - params:
      'match[]': # scrape only required metrics from in-cluster prometheus
        - '{__name__="container_network_transmit_bytes_total", namespace!~".*-tenant|openshift-.*|kube-.*"}'
        - '{__name__=~"kube_pod_.*container_resource_limits", namespace!~".*-tenant|openshift-.*|kube-.*"}'
        - '{__name__="kube_pod_labels", namespace!~".*-tenant|openshift-.*|kube-.*"}'
        - '{__name__="container_last_seen", namespace!~".*-tenant|openshift-.*|kube-.*"}'
        - '{__name__="argocd_app_info", namespace!~".*-tenant|openshift-.*|kube-.*"}'
        - '{__name__="controller_runtime_reconcile_errors_total", namespace!~".*-tenant|openshift-.*|kube-.*"}'
        - '{__name__="controller_runtime_reconcile_total", namespace!~".*-tenant|openshift-.*|kube-.*"}'
        - '{__name__="kube_pod_status_unschedulable", namespace!~".*-tenant|openshift-.*|kube-.*"}'
        - '{__name__="kube_pod_container_status_waiting_reason", namespace!~".*-tenant|openshift-.*|kube-.*"}'
        - '{__name__="kube_pod_status_phase", namespace!~".*-tenant|openshift-.*|kube-.*"}'
        - '{__name__="kube_pod_status_unschedulable", namespace!~".*-tenant|openshift-.*|kube-.*"}'
        - '{__name__="kube_persistentvolume_status_phase", namespace!~".*-tenant|openshift-.*|kube-.*"}'
        - '{__name__="kube_resourcequota", namespace!~".*-tenant|openshift-.*|kube-.*"}'
    relabelings:
    # override the target's address by the prometheus-k8s service name.
    - action: replace
      targetLabel: __address__
      replacement: prometheus-k8s.openshift-monitoring.svc:9091
    # remove the default target labels as they aren't relevant in case of federation.
    - action: labeldrop
      regex: pod|namespace|service|endpoint|container
    # 30s interval creates 4 scrapes per minute
    # prometheus-k8s.svc x 2 ms-prometheus x (60s/ 30s) = 4
    interval: 30s
    # ensure that the scraped labels are preferred over target's labels.
    honorLabels: true
    port: web
    scheme: https
    path: "/federate"
    bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
    tlsConfig:
      serverName: prometheus-k8s.openshift-monitoring.svc
      ca:
        configMap: # automatically created by serving-ca operator
          key: service-ca.crt
          name: openshift-service-ca.crt
---
# Create ServiceMonitor for user workload prometheus Federation
apiVersion: monitoring.rhobs/v1
kind: ServiceMonitor
metadata:
  name: appstudio-federate-uwm-smon
  namespace: appstudio-monitoring
  labels:
    kubernetes.io/part-of: appstudio-federate-ms
    monitoring.rhobs/stack: appstudio-federate-ms
spec:
  selector: # use the prometheus service to create a "dummy" target.
    matchLabels:
      app.kubernetes.io/managed-by: observability-operator
      app.kubernetes.io/name: appstudio-federate-ms-prometheus
  endpoints:
  - params:
      'match[]': # scrape only required metrics from UWM prometheus
        - '{__name__=~".*"}' # all the metrics from UWM prometheus
    relabelings:
    # override the target's address by the prometheus-UWM service name.
    - action: replace
      targetLabel: __address__
      replacement: prometheus-user-workload.openshift-user-workload-monitoring.svc:9092
    # remove the default target labels as they aren't relevant in case of federation.
    - action: labeldrop
      regex: pod|namespace|service|endpoint|container
    # 30s interval creates 4 scrapes per minute
    # prometheus-user-workload.svc x 2 ms-prometheus x (60s/ 30s) = 4
    interval: 30s
    # ensure that the scraped labels are preferred over target's labels.
    honorLabels: true
    port: web
    scheme: https
    path: "/federate"
    bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
    tlsConfig:
      serverName: prometheus-user-workload.openshift-user-workload-monitoring.svc
      ca:
        configMap: # automatically created by serving-ca operator
          key: service-ca.crt
          name: openshift-service-ca.crt
